# Terminology

This topic introduces the major concepts involved in data asset management.



## About Storage Policy

To help you understand data storage policy related concepts and customize data storage policies, definition and description of related terms are as follows.

### Storage group

Data storage policy group supports separate storage policy configuration of different projects or domains.

### Storage type

Separate storage by data type (AI raw data, AI normalized data, DI data, and generic data). An API is provided to retrieved each type of stored data. 

### Storage time

Data retention time. Available options are 1 month, 3 months, 6 months, 1 year, 2 years, 3 years, 5 years, 10 years, 15 years, and 20 years.



## About Stream Analytics

To help you understand stream data processing concepts and use the stream data processing service to develop data processing jobs, definition and description of related terms are as follows.

### Stream data

Broadly speaking, the generation of data can be considered as a series of discrete events. When drawing these discrete events on a time axis, an event stream or data stream is formed. Streaming data consist of these endless event streams.

Both offline data and streaming data are normally sent as logs. Unlike traditional offline data, streaming data are generated continuously by a lot of data sources. However, the size of the streaming data is normally smaller than that of the offline data.

The common sources of streaming data can be the devices connected to a data center, the telemetry data of devices, and the log files generated by mobile or web applications.

### Stream analytics

In general, stream analytics has the following characteristics:

- Real-time and unbounded data streaming: The computation the engine processes is real-time and streaming, and the data streams are subscribed and consumed by stream computing in chronological order. Because data are generated continuously, the data streams are integrated to the streaming system continuously. For example, website access log is a type of streaming data, the log continuously records data as long as the website is online. Thus, the streaming data are always real-time and unbounded.
- Continuous and efficient computation: The computation models of stream computing are “event triggered”. The trigger is the unbounded streaming data mentioned in the previous section. Once new streaming data are sent to the system, the system immediately initiates and performs a computation task. Therefore, stream computing is a continuous process.
- Streaming and real-time data integration: The result of stream computing triggered by streaming data is recorded directly into the destination data storage. For example, the data can be directly written into the relational database (RDS) for report rendering. Therefore, the computing results of the streaming data are continuously recorded into the target data storage.

### Data type

EnOS Stream Processing Engine supports multiple data types with specific data processing templates. The data type of a measure point telemetry is defined when configuring the device model.

### Data processing strategy

Unified window aggregation scheme for the data of the same device model, which consists of an input point, output point, threshold, interpolation strategy, algorithm, and window size.

### Event time

In general, event time (time when an event occurs) is used in AI data aggregation. More precisely, every event has a corresponding timestamp, and the timestamp is part of the data record. Event time is actually a timestamp. When event time is used to define time windows, the stream processing engine can deal with disorderly time flow and variable event time deviation, and compute meaningful results based on the actual time of events.

### Time window

EnOS Stream Processing Engine is based on time windows (micro-batch model) and processes data at the specified window size (interval of batch size). Windowing is simply the notion of taking a data source and chopping it up along temporal boundaries into finite chunks for processing, which determines how often a stream computing task gets the data. EnOS Streaming Processing Engine supports tumbling window.

### Tumbling window

Tumbling windows have a fixed size and do not overlap. Data belonging to a window will be aggregated with the specified method. For example, if you specify a tumbling window with a size of 5 minutes, the current window will be evaluated, and a new window will be started every five minutes. See the example in the following figure.

.. image:: media/window_type.png

### Window latency

Generally, when a window closes, the data processing in the window should have been completed, and a new window will be started. However, device data transfer might be delayed because of various factors like device failure and transmission efficiency. Latency setting is introduced to specify the extended validity time of the window after it closes. Late data arriving within the allowed lateness will be added to the window and computed again. Late data arriving after the allowed lateness will be ignored. In the following example, window size is 5 minutes, and window2 contains data falling in the time range of 11:00 - 11:05. If latency is not enabled, window2 will be closed at 11:05, and data1 and data2 that are arriving late will be ignored. If a latency of 5 minutes is enabled, data1 will be added to window2 for computing again, but data2 will be ignored.

.. image:: media/latency_setting.png



## About Data Subscription

To help you understand data subscription related concepts and use the data subscription service to develop applications, definition and description of related terms are as follows.

### Kafka

Kafka is a distributed messaging system, which receives streams of data from the data producers and stores the data in categories called topics. Data consumers can simply read the stored data when needed, thus realizing asynchronous non-blocking I/O.

### Topic

Message topic, which categorizes messages and stores received data streams.

### Partition

Data saved in a topic are divided into partitions with specific logic. Partitions determine the number of producers or consumers who can write and read data in the topic. For example, if a topic has 3 partitions, the producer can start 3 processes to write data in the topic, and the consumer can have 3 processes to read data from the topic.

### Data producer

A data producer is the device that uploads data to EnOS Cloud. A data producer is also called a message publisher.

### Data consumer

A data consumer is the data subscriber. A consumer group is a collection of consumers who can receive and consume the same messages with the same logic.

### Consumer instance

An object instance of consumer. Different consumer instances can run different processes or be run on different servers. Thread pools are configured for a consumer instance to consume messages.

### Group consumption

All the consumer instances in a consumer group can consume messages in a topic averagely. For example, a topic has 9 messages, and a consumer group has 3 consumer instances, then a consumer instance can consume 3 messages in the group consumption mode.

### Sequential publish

For a specific topic, the client server publishes messages in a sequential order.

### Sequential consumption

For a specific topic, messages are received in a sequential order. That is, the message sent first must be received by the client first.

### Message pileup

Data producer sends messages to the subscription service, but the consumer fails to consume all the messages within a specific time because of limited capability. The messages not being consumed are saved in the subscription service, which is called message pileup.

### Message Filtering

Subscriber can filter messages with specific conditions so as to receive filtered data only. Message filters can be configured in the subscription service.



<!--end-->


